# Reactive programming vs synchronised 
Reactive programming is also called Event based or asynchronise programming model. A reactive system is an architectural style that allows multiple individual requests to be processed by a single thread for each cpu core.  Synchronised is the alternate  programming model, where each request is handled by a individual thread.  Reactive programming is having advantage if number concurrent requests to the server is large and processing of each request need lot of IO or sleeps/waits during the processing. Reactive programming model is relative new in Java world, But in the linux kernel the epoll and AsyncIO is been introduced or supported more then decade back. Reactive programming is implemented on the foundations of epoll and asyncIO to reduce the system calls overhead. system call are expensive and can impact latency as-well throughput. 

In this Perf Test, Comparison between a Netty server a Asynchronous model vs Tomacat  a Synchronous model is compared.  Netty uses few number of threads proportional to the number of cpu cores  to process large number of requests. On the Other hand Tomcat uses separate thread for each request. Suppose if there are 2000 concurrent requests on 32 core machine  then Netty uses around 32 active threads vs Tomcat uses 2000 active threads to processes the requests. Due to this if the number  of request are large and each request need lot of waits during processing of thread like waiting for database response then Netty Performs well in terms of latency as well as throughput. Tomcat spends lot of cpu cycles in context switches. Netty has its own memory allocator for buffers, it doesn't waste memory bandwidth by filling buffers with zeros, Netty implements a jemalloc variant of memory allocation by bypassing jvm GC. 


## Perf Test-1 :   sleep request

Description: Rest server does a sleep of 100ms as part of request processing. sleep of 100ms is emulate a wait like waiting for the database response or the delay introduced by other backend servers which is very common in Rest servers. The load is generated by the tool "ab", concurrent request ranging from 200 to 2600 are generated. 

```
Load generator: ab -n 90000 -c 200 http://localhost:8080/sleep
Flow of packets:  load generator -> Netty/Tomacat . 100ms delay is created inside the request processing.
Tomcat command: java -jar ./Tomcat_sync-0.0.1-SNAPSHOT.jar
Netty Command: java -jar ./Netty_example-0.0.1-SNAPSHOT.jar 
Total number of Request in all the tests =  90000
number of cpu cores inside the machine: 32 cores
```

Test Results:

<table border=1>
<thead>
<tr>
<th>Test-Description</th>
<th>Tomcat</th>
<th>Netty</th>
<th> Comment </th>
</tr>
<tr>
<th>1) concurrency=200 </th>
<th>latency=101ms, cpu= 90/3200 </th>
<th>latency=101ms, cpu= 100/3200</th>
<th>100ms is the waiting time inside the web request. Tomcat and Netty Perform at the same level.  </th>
</tr>
<tr>
<th>3) concurrency=800 </th>
<th>latency=111ms, cpu=350/3200 </th>
<th>latency=103ms, cpu=350/3200 </th>
<th>Netty is better slightly.</th>
</tr>

</tbody></table>


# Summary :

 -  As the number of concurrent IO bound requests increases the latency and throughput gap between Netty and Tomcat will increases. The main reason is Tomcat spends lot of cpu cycles in switching user to kernel space with futex system calls during the IO time. futex call will be used when a thread waits for IO or for syncronization purpose.
 -  Netty is more suitable if the Rest server need to handle requests that need lot of backend communications like databases,rest servers,...etc.  The latency gap is more in Perf Test-1 when compare to Perf-Test-2 because the waiting period is 100ms in Perf-Test-1 when compare to 50ms in other. 
 - The performance gap between Tomcat and Netty can be less if the load is cpu bound and less number of concurrent requests.  

 

# Reactive programming vs synchronised 
Reactive programming is also called Event based or asynchronise programming model. A reactive system is an architectural style that allows multiple individual requests to be processed by a single thread for each cpu core.  Synchronised is the alternate  programming model, where each request is handled by a individual thread.  Reactive programming is having advantage if number concurrent requests to the server is large and processing of each request need lot of IO or sleeps/waits during the processing. Reactive programming model is relative new in Java world, But in the linux kernel the epoll and AsyncIO is been introduced or supported more then decade back. Reactive programming is implemented on the foundations of epoll and asyncIO to reduce the system calls overhead. system call are expensive and can impact latency as-well throughput. 

In this Perf Test, Comparison between a Netty server a Asynchronous model vs Tomacat  a Synchronous model is compared.  Netty uses few number of threads proportional to the number of cpu cores  to process large number of requests. On the Other hand Tomcat uses separate thread for each request. Suppose if there are 2000 concurrent requests on 32 core machine  then Netty uses around 32 active threads vs Tomcat uses 2000 active threads to processes the requests. Due to this if the number  of request are large and each request need lot of waits during processing of thread like waiting for database response then Netty Performs well in terms of latency as well as throughput. Tomcat spends lot of cpu cycles in context switches and futex system calls. Netty has its own memory allocator for buffers, it doesn't waste memory bandwidth by filling buffers with zeros, Netty implements a jemalloc variant of memory allocation by bypassing jvm GC. 




## Perf Test-1 :   web request

Description: IN this test there will be 3-tier, load generator, Rest server and eacho server.  Rest server does a web request using a http client as part of rest call. request at echo server  sleeps for a period of 50ms and respond back to the rest server. Instead of echoserver there can be datbases or any other server. The load is generated by the tool "ab", concurrent request ranging from 200 to 2600 are generated.

```
Load generator: ab -n 90000 -c 200 http://localhost:8080/sleep
Flow of packets:  ab(load generator) -> Rest server(Netty/Tomacat) -> echo server (echo request with 50ms delay is created inside the request processing).
Tomcat command: java -jar ./Tomcat_sync-0.0.1-SNAPSHOT.jar
Netty Command: java -jar ./Netty_example-0.0.1-SNAPSHOT.jar 
Total number of Request in all the tests =  90000
number of cpu cores inside the machine: 32 cores
```

Test Results:

<table border=1>
<thead>
<tr>
<th>Test-Description</th>
<th>Tomcat</th>
<th>Netty</th>
<th> Comment </th>
</tr>
<tr>
<th>1) concurrency=200 </th>
<th>latency=101ms, cpu= 90/3200 </th>
<th>latency=101ms, cpu= 100/3200</th>
<th>100ms is the waiting time inside the web request. Tomcat and Netty Perform at the same level.  </th>
</tr>
<tr>
<th>3) concurrency=800 </th>
<th>latency=105ms, cpu=700/3200 </th>
<th>latency=82ms, cpu=400/3200 </th>
<th>Netty is better by 20% in latency and 80% in cpu savings.</th>
</tr>

</tr>
<tr>
<th>3) concurrency=1800 </th>
<th>latency=191ms, cpu=840/3200 </th>
<th>latency=157ms, cpu=480/3200 </th>
<th>Netty is better by 20% in latency and 80% in cpu savings.</th>
</tr>

</tbody></table>

# Analysis of logs at Netty:

```
context switches: 300k
futex call : 3.9k
Total calls: 303k

 java -Dreactor.netty.ioWorkerCount=8 -jar ./Netty_example-0.0.1-SNAPSHOT.jar
 
 <rank> <IPC><instructions>(Percentage) faults:<> cs:<> futex:<>(Percentage) <thread name> (pid)
1, 1.000  Inst: 55(100/0) fault:25497 cs:302110 futex:3919(100) read:832530 write:1273335 Entire-JVM
2, 1.000  Inst: 1(1/1) fault:0 cs:0 futex:0(0) read:0 write:0 "server"
3, 1.000  Inst: 1(1/3) fault:1542 cs:34517 futex:35(0) read:104711 write:145440 "reactor-http-epoll-8"
4, 1.000  Inst: 1(1/5) fault:1769 cs:31528 futex:33(0) read:113127 write:159234 "reactor-http-epoll-7"
5, 1.000  Inst: 1(1/7) fault:1942 cs:35935 futex:31(0) read:107978 write:147349 "reactor-http-epoll-6"
6, 1.000  Inst: 1(1/9) fault:2315 cs:37491 futex:37(0) read:107054 write:144645 "reactor-http-epoll-5"
7, 1.000  Inst: 1(1/10) fault:1942 cs:36703 futex:32(0) read:105311 write:143832 "reactor-http-epoll-4"
8, 1.000  Inst: 1(1/12) fault:2014 cs:38992 futex:34(0) read:108062 write:145856 "reactor-http-epoll-3"
9, 1.000  Inst: 1(1/14) fault:1733 cs:36328 futex:31(0) read:105511 write:144476 "reactor-http-epoll-2"
10, 1.000  Inst: 1(1/16) fault:1179 cs:49079 futex:26(0) read:80776 write:242503 "reactor-http-epoll-1"
11, 1.000  Inst: 1(1/18) fault:1274 cs:45 futex:115(2) read:0 write:0 "VM Thread" os_prio=0 tid=0x00007fbc943c6000 nid=0x12894 runnable
12, 1.000  Inst: 1(1/20) fault:88 cs:403 futex:806(20) read:0 write:0 "VM Periodic Task Thread" os_prio=0 tid=0x00007fbc9442f000 nid=0x128a8 waiting on condition

```

# Analysis of logs at tomacat:

```
context switches: 1424k
futex call : 1200k
Total calls= 2624k
flow of packets: epoll thread(32) -> http-nio(1800: one thread per request)-> ...

1800 threads * 0.6k  = 1200k calls
 java -jar ./Tomcat_sync-0.0.1-SNAPSHOT.jar --server.tomcat.max-threads=4020
 
1, 1.000  Inst: 1850(100/0) fault:62384 cs:1424920 futex:1200702(100) read:1137823 write:1525846 Entire-JVM
2, 1.000  Inst: 1(0/0) fault:233 cs:17960 futex:6510(0) read:21833 write:29936 "reactor-http-epoll-9"
3, 1.000  Inst: 1(0/0) fault:123 cs:19107 futex:7175(0) read:23361 write:31679 "reactor-http-epoll-8"
4, 1.000  Inst: 1(0/0) fault:59 cs:17454 futex:6158(0) read:21081 write:28915 "reactor-http-epoll-7"
5, 1.000  Inst: 1(0/0) fault:22 cs:16318 futex:5495(0) read:19462 write:27027 "reactor-http-epoll-6"
6, 1.000  Inst: 1(0/0) fault:249 cs:19463 futex:7589(0) read:24055 write:32810 "reactor-http-epoll-5"
...
...
31, 1.000  Inst: 1(0/1) fault:25 cs:18798 futex:6983(0) read:22947 write:31345 "reactor-http-epoll-11"
32, 1.000  Inst: 1(0/1) fault:230 cs:17771 futex:6222(0) read:21423 write:29336 "reactor-http-epoll-10"
33, 1.000  Inst: 1(0/1) fault:74 cs:17405 futex:5929(0) read:20732 write:28456 "reactor-http-epoll-1"
34, 1.000  Inst: 1(0/1) fault:14 cs:226 futex:558(0) read:112 write:289 "http-nio-8080-exec-999"
35, 1.000  Inst: 1(0/1) fault:35 cs:231 futex:564(0) read:115 write:294 "http-nio-8080-exec-998"
36, 1.000  Inst: 1(0/1) fault:13 cs:229 futex:574(0) read:104 write:276 "http-nio-8080-exec-997"
37, 1.000  Inst: 1(0/1) fault:26 cs:224 futex:563(0) read:110 write:281 "http-nio-8080-exec-996"
38, 1.000  Inst: 1(0/2) fault:14 cs:228 futex:560(0) read:123 write:347 "http-nio-8080-exec-995"

```


# Summary :

 -  Root Cause and Impact: In syncronization programming, Due to large number of concurrent threads there will be large number of futexe system calls and context switches, due to this cpu cycles consumption is large and increase in latency.
    -  In Tomcat :  context switches: 1424k , futex calls: 1200k , cpu consumption: 840 , latency: 191ms
    -  In Netty :  context switches:  300k futexes: 3.9k , cpu: 480 latency: 157ms
    -  Futex calls are used for IO wait and syncronization purpose.
 - The performance gap between Tomcat and Netty can be less if the request is cpu bound  and less number of concurrent requests. Netty is more suitable if the Rest server need to handle large number of requests , and each request need lot of backend communications like databases,rest servers,...etc. 

# Solution :
 -  Using Async or reactive models: Few Kernel threads. But it is asyncronous programming which is not a non-sequential programming. 
    -   Advantages: Relatively Mature.
    -   Disadvantages:  little bit difficult to debug due to asyncronous programming.
 -  Using Java Fibers : Large number of User level threads along with few kernel threads, this model is very similar to golang channels. Eventhough User level threads are large in number the overhead of futexs and context switches will be less due to less kernel threads.
    - Advantages: Syncronous programming using user level threads.
    - Disadvantages: Relatively New technology.

## Papers related to syscall impact on performance:
 -   [syscall impact in high end NoSQL database](https://github.com/naredula-jana/Jiny-Kernel/blob/master/doc/HighThroughputDatabaseForBigData.pdf) .
 -   [Minimising syscall : Golang apps in ring-0](https://github.com/naredula-jana/Jiny-Kernel/blob/master/doc/GolangAppInRing0.pdf).
  -  [Netty uses Jemalloc varient for memory allocation](https://github.com/naredula-jana/Jiny-Kernel/blob/master/doc/malloc_paper_techpulse_submit_final.pdf).
  -  [Async-Netty Vs sync-Tomcat performance results](https://www.slideshare.net/brendangregg/rxnetty-vs-tomcat-performance-results).

 
